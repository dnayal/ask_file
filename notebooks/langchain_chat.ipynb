{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain_core.messages import HumanMessage, AIMessage\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import START, MessagesState, StateGraph\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "from typing import Sequence\n",
    "from langchain_core.messages import BaseMessage\n",
    "from langgraph.graph.message import add_messages\n",
    "from typing_extensions import Annotated, TypedDict\n",
    "\n",
    "from langchain_core.messages import SystemMessage, trim_messages\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"]=\"true\"\n",
    "os.environ[\"LANGCHAIN_ENDPOINT\"]=\"https://eu.api.smith.langchain.com\"\n",
    "os.environ[\"LANGCHAIN_API_KEY\"]=\"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\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"]=\"pr-juicy-equality-90\"\n",
    "\n",
    "os.environ[\"NVIDIA_API_KEY\"] = \"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise NVIDIA model for chat\n",
    "model = ChatNVIDIA(model=\"meta/llama-3.1-405b-instruct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Namaste Deepak! It's nice to meet you. How are you doing today? Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Namaste Deepak! It's nice to meet you. How are you doing today? Is there something I can help you with or would you like to chat?\", 'token_usage': {'prompt_tokens': 17, 'total_tokens': 50, 'completion_tokens': 33}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-a8f60ef1-fb20-4893-990a-b59e36244e49-0', usage_metadata={'input_tokens': 17, 'output_tokens': 33, 'total_tokens': 50}, role='assistant')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send the first message\n",
    "model.invoke([HumanMessage(content=\"Hi! I am Deepak\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"I don't have any information about your name. I'm a large language model, I don't have personal interactions or memories, and I don't retain information about individual users. Each time you interact with me, it's a new conversation and I don't have any prior knowledge about you. If you'd like to tell me your name, I'd be happy to chat with you!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"I don't have any information about your name. I'm a large language model, I don't have personal interactions or memories, and I don't retain information about individual users. Each time you interact with me, it's a new conversation and I don't have any prior knowledge about you. If you'd like to tell me your name, I'd be happy to chat with you!\", 'token_usage': {'prompt_tokens': 16, 'total_tokens': 94, 'completion_tokens': 78}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-6540a1a0-be4d-4dd0-aa11-b946cd82f3d2-0', usage_metadata={'input_tokens': 16, 'output_tokens': 78, 'total_tokens': 94}, role='assistant')"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send follow up message to see if the model remembers - it wont\n",
    "model.invoke([HumanMessage(content=\"What was my name?\")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Your name is Deepak!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your name is Deepak!', 'token_usage': {'prompt_tokens': 50, 'total_tokens': 56, 'completion_tokens': 6}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-fdbd93f5-2c85-479e-9e6c-82d14dd9cf86-0', usage_metadata={'input_tokens': 50, 'output_tokens': 6, 'total_tokens': 56}, role='assistant')"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# send full message history to get the context\n",
    "model.invoke(\n",
    "    [\n",
    "        HumanMessage(content=\"Hi! I am Deepak\"),\n",
    "        AIMessage(content=\"Hi Deepak! Nice to meet you! Is there something I can help you with?\"),\n",
    "        HumanMessage(content=\"What was my name?\")\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"You are a helpful translator. Answer all questions in {language}.\"\n",
    "        ),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Message Persistence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "trimmer = trim_messages(\n",
    "    max_tokens = 100,\n",
    "    strategy = \"last\",\n",
    "    token_counter = model,\n",
    "    include_system = True,\n",
    "    allow_partial = False,\n",
    "    start_on = \"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "f-string: unmatched '[' (1335967762.py, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[127], line 10\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"TRIM: ========={trimmed_messages[\"messages\"]}=========\")\u001b[0m\n\u001b[0m                                              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m f-string: unmatched '['\n"
     ]
    }
   ],
   "source": [
    "class State(TypedDict):\n",
    "    messages: Annotated[Sequence[BaseMessage], add_messages]\n",
    "    language: str\n",
    "\n",
    "workflow = StateGraph(state_schema=State)\n",
    "\n",
    "def call_model(state: State):\n",
    "    chain = prompt | model\n",
    "    trimmed_messages = trimmer.invoke(state[\"messages\"])\n",
    "    print(f\"TRIM: ========={trimmed_messages[-1]}=========\")\n",
    "    response = chain.invoke(\n",
    "        {\"messages\":trimmed_messages, \"language\":state[\"language\"]}\n",
    "    )\n",
    "    return {\"messages\": response}\n",
    "\n",
    "workflow.add_edge(START, \"model\")\n",
    "workflow.add_node(\"model\", call_model)\n",
    "\n",
    "memory = MemorySaver()\n",
    "app = workflow.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This enables us to support multiple conversation threads with a single application, a common requirement when your application has multiple users.\n",
    "config = {\"configurable\": {\"thread_id\":\"abc123\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIM: =========[HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='d573e0d4-02b3-466a-ab7e-3d8da8b97681'), HumanMessage(content='Hi! I am Myra', additional_kwargs={}, response_metadata={}, id='977e4a0d-da1b-46db-804c-5aaf51b25d85')]=========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='d573e0d4-02b3-466a-ab7e-3d8da8b97681'),\n",
       " HumanMessage(content='Hi! I am Myra', additional_kwargs={}, response_metadata={}, id='977e4a0d-da1b-46db-804c-5aaf51b25d85'),\n",
       " AIMessage(content='Nice to meet you, Myra! How can I assist you with translation today?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Nice to meet you, Myra! How can I assist you with translation today?', 'token_usage': {'prompt_tokens': 44, 'total_tokens': 61, 'completion_tokens': 17}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-9ae33da5-620b-49e6-a656-c1efb66e5510-0', usage_metadata={'input_tokens': 44, 'output_tokens': 17, 'total_tokens': 61}, role='assistant')]"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"Hi! I am Myra\"\n",
    "language = \"English\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages, \"language\": language}, config)\n",
    "\n",
    "output[\"messages\"]#[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRIM: =========[HumanMessage(content='Hi! I am Myra', additional_kwargs={}, response_metadata={}, id='aca961b1-110d-4c42-a77b-46d89edcbbf5'), AIMessage(content=\"Hello Myra! Nice to meet you! I'm happy to chat with you and help with any questions you might have. How's your day going so far? Do you have something on your mind that you'd like to talk about or ask about? I'm all ears!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Hello Myra! Nice to meet you! I'm happy to chat with you and help with any questions you might have. How's your day going so far? Do you have something on your mind that you'd like to talk about or ask about? I'm all ears!\", 'token_usage': {'prompt_tokens': 117, 'total_tokens': 173, 'completion_tokens': 56}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-a57b7c31-09b6-445c-8212-8a876508a446-0', usage_metadata={'input_tokens': 117, 'output_tokens': 56, 'total_tokens': 173}, role='assistant'), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='2aef551c-01b1-4d5b-87bc-27b1b9754203'), AIMessage(content='Your name is Myra!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your name is Myra!', 'token_usage': {'prompt_tokens': 105, 'total_tokens': 111, 'completion_tokens': 6}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-7a369f3a-ded1-4f21-9b19-c7224f33c565-0', usage_metadata={'input_tokens': 105, 'output_tokens': 6, 'total_tokens': 111}, role='assistant'), HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='3912ce31-e98a-4e9e-ae76-b20374c4a44a')]=========\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='Hi! I am Myra', additional_kwargs={}, response_metadata={}, id='e379d1cb-bd48-42e9-afb5-ebd8935799a1'),\n",
       " AIMessage(content='Hello Myra! Nice to meet you. How can I help you today? Do you need some translation help or just want to chat?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Hello Myra! Nice to meet you. How can I help you today? Do you need some translation help or just want to chat?', 'token_usage': {'prompt_tokens': 34, 'total_tokens': 62, 'completion_tokens': 28}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-8c38c672-5f9f-4b49-bd21-5293f5c40e64-0', usage_metadata={'input_tokens': 34, 'output_tokens': 28, 'total_tokens': 62}, role='assistant'),\n",
       " HumanMessage(content=\"My dad's name is Deepak\", additional_kwargs={}, response_metadata={}, id='fcdbac05-2e98-4cad-a32e-041e829f015a'),\n",
       " AIMessage(content='That\\'s nice! Deepak is a popular Indian name. It means \"lamp\" or \"light\" in Sanskrit. Is there something specific you\\'d like to talk about or ask regarding your dad or his name? I\\'m here to help!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'That\\'s nice! Deepak is a popular Indian name. It means \"lamp\" or \"light\" in Sanskrit. Is there something specific you\\'d like to talk about or ask regarding your dad or his name? I\\'m here to help!', 'token_usage': {'prompt_tokens': 79, 'total_tokens': 129, 'completion_tokens': 50}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-52d8de12-594f-4993-96ed-90b80d6550af-0', usage_metadata={'input_tokens': 79, 'output_tokens': 50, 'total_tokens': 129}, role='assistant'),\n",
       " HumanMessage(content=\"My mother's name is Neha\", additional_kwargs={}, response_metadata={}, id='ecea4c86-e0a5-4549-b170-c32274a8e7a3'),\n",
       " AIMessage(content='That\\'s a lovely name! Neha is a common Indian feminine given name that means \"love\", \"rain\", or \"eyes\" in Sanskrit. It\\'s a sweet and endearing name. Do you have a close relationship with your mom, or is there something special you\\'d like to share about her?', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'That\\'s a lovely name! Neha is a common Indian feminine given name that means \"love\", \"rain\", or \"eyes\" in Sanskrit. It\\'s a sweet and endearing name. Do you have a close relationship with your mom, or is there something special you\\'d like to share about her?', 'token_usage': {'prompt_tokens': 102, 'total_tokens': 165, 'completion_tokens': 63}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-736a7ebd-ace3-4141-9404-d898f55b62cd-0', usage_metadata={'input_tokens': 102, 'output_tokens': 63, 'total_tokens': 165}, role='assistant'),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='dcd62328-2bae-4e33-86f8-606fd10d988a'),\n",
       " AIMessage(content=\"Unfortunately, I don't have that information. You didn't share your name with me. Would you like to tell me what your name is?\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Unfortunately, I don't have that information. You didn't share your name with me. Would you like to tell me what your name is?\", 'token_usage': {'prompt_tokens': 113, 'total_tokens': 142, 'completion_tokens': 29}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-b45d2cfb-daf7-4b49-b304-c2b1cf760e60-0', usage_metadata={'input_tokens': 113, 'output_tokens': 29, 'total_tokens': 142}, role='assistant'),\n",
       " HumanMessage(content=\"What is my dad's name?\", additional_kwargs={}, response_metadata={}, id='9582b80d-222c-407d-99cc-da75ec46874e'),\n",
       " AIMessage(content=\"I don't have any information about your personal life, including the names of your family members. As a translator, our conversation just started, and I don't have any prior knowledge about you. Would you like to talk about something else? I'm here to help with any questions or translations!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"I don't have any information about your personal life, including the names of your family members. As a translator, our conversation just started, and I don't have any prior knowledge about you. Would you like to talk about something else? I'm here to help with any questions or translations!\", 'token_usage': {'prompt_tokens': 79, 'total_tokens': 138, 'completion_tokens': 59}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-3311a994-c34d-4663-8247-2c5572bac363-0', usage_metadata={'input_tokens': 79, 'output_tokens': 59, 'total_tokens': 138}, role='assistant'),\n",
       " HumanMessage(content=\"What is my mother's name?\", additional_kwargs={}, response_metadata={}, id='ecfdbba1-108b-441f-af1e-2fcb18dfbc5c'),\n",
       " AIMessage(content=\"I still don't have any information about your personal life or your family members. As a translator, I can help answer general questions, translate text, or provide information on various topics, but I don't have any personal information about you or your family. Would you like to ask about something else? I'm here to help!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"I still don't have any information about your personal life or your family members. As a translator, I can help answer general questions, translate text, or provide information on various topics, but I don't have any personal information about you or your family. Would you like to ask about something else? I'm here to help!\", 'token_usage': {'prompt_tokens': 111, 'total_tokens': 177, 'completion_tokens': 66}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-893ecb9b-0912-42b9-a407-aea57410c84a-0', usage_metadata={'input_tokens': 111, 'output_tokens': 66, 'total_tokens': 177}, role='assistant'),\n",
       " HumanMessage(content='Hi! I am Myra', additional_kwargs={}, response_metadata={}, id='aca961b1-110d-4c42-a77b-46d89edcbbf5'),\n",
       " AIMessage(content=\"Hello Myra! Nice to meet you! I'm happy to chat with you and help with any questions you might have. How's your day going so far? Do you have something on your mind that you'd like to talk about or ask about? I'm all ears!\", additional_kwargs={}, response_metadata={'role': 'assistant', 'content': \"Hello Myra! Nice to meet you! I'm happy to chat with you and help with any questions you might have. How's your day going so far? Do you have something on your mind that you'd like to talk about or ask about? I'm all ears!\", 'token_usage': {'prompt_tokens': 117, 'total_tokens': 173, 'completion_tokens': 56}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-a57b7c31-09b6-445c-8212-8a876508a446-0', usage_metadata={'input_tokens': 117, 'output_tokens': 56, 'total_tokens': 173}, role='assistant'),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='2aef551c-01b1-4d5b-87bc-27b1b9754203'),\n",
       " AIMessage(content='Your name is Myra!', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Your name is Myra!', 'token_usage': {'prompt_tokens': 105, 'total_tokens': 111, 'completion_tokens': 6}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-7a369f3a-ded1-4f21-9b19-c7224f33c565-0', usage_metadata={'input_tokens': 105, 'output_tokens': 6, 'total_tokens': 111}, role='assistant'),\n",
       " HumanMessage(content='What is my name?', additional_kwargs={}, response_metadata={}, id='3912ce31-e98a-4e9e-ae76-b20374c4a44a'),\n",
       " AIMessage(content='Still the same! Your name is Myra.', additional_kwargs={}, response_metadata={'role': 'assistant', 'content': 'Still the same! Your name is Myra.', 'token_usage': {'prompt_tokens': 126, 'total_tokens': 136, 'completion_tokens': 10}, 'finish_reason': 'stop', 'model_name': 'meta/llama-3.1-405b-instruct'}, id='run-279dc974-e2be-403a-baf5-a9dd6a3b9939-0', usage_metadata={'input_tokens': 126, 'output_tokens': 10, 'total_tokens': 136}, role='assistant')]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What is my name?\"\n",
    "\n",
    "input_messages = [HumanMessage(query)]\n",
    "output = app.invoke({\"messages\": input_messages}, config)\n",
    "\n",
    "output[\"messages\"]#[-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
